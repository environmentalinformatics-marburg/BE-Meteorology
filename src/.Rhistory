# Read datasets
df_met_m_from_d = readRDS(paste0(path_rdata, "/df_met_m_from_d.rds"))
df_met_d_meta = readRDS(paste0(path_rdata, "/df_met_d_meta.rds"))
# Mean monthly temperature by exploratory and landcover
ggplot(df_met_m_from_d, aes(x = grp_months, y = Ta_200, fill = grp_belc)) +
geom_boxplot(position = "dodge") +
scale_fill_manual(values = c("#a6cee3", "#1f78b4", "#b2df8a", "#33a02c",
"#fb9a99", "#e31a1c","#DBD413")) +
geom_vline(xintercept = seq(1.5, 12, 1), linetype = "dotted") +
labs(list(x = "Month", y = "Mean air temperature (Â°C) 2009 to 2016")) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
theme_bw()
# Mean monthly precipitation by exploratory and landcover
ggplot(df_met_m_from_d, aes(x = grp_months, y = precipitation_radolan, fill = grp_belc)) +
geom_boxplot(position = "dodge") +
scale_fill_manual(values = c("#a6cee3", "#1f78b4", "#b2df8a", "#33a02c",
"#fb9a99", "#e31a1c","#DBD413")) +
geom_vline(xintercept = seq(1.5, 12, 1), linetype = "dotted") +
labs(list(x = "Month", y = "Mean monthly precipitation (mm) 2009 to 2016")) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
theme_bw()
# Mean monthly precipitation by landcover
tmp = melt(df_met_m_from_d[, c(19, 36, 48, 51)], id.vars = c("grp_lc", "grp_months"))
head(tmp)
tmp$grp = paste(tmp$variable, tmp$grp_lc, sep = "_")
ggplot(tmp, aes(x = grp_months, y = value, fill = grp)) +
geom_boxplot(position = "dodge") +
guides(fill=guide_legend(title=NULL)) +
scale_fill_manual(values = c("#a6cee3", "#1f78b4", "#fb9a99", "#e31a1c"),
breaks=c("Ta_200_cold_days_G", "Ta_200_cold_days_W",
"Ta_200_summer_days_G", "Ta_200_summer_days_W"),
labels=c("Cold days grassland", "Cold days forest",
"Summer days grassland", "Summer days forest")) +
geom_vline(xintercept = seq(1.5, 12, 1), linetype = "dotted") +
labs(list(x = "Month", y = "Number of days 2009 to 2016")) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
theme_bw()
summary(df_met_m_from_d$Ta_200[substr(df_met_m_from_d$EPID, 1, 1) == "A"])
summary(df_met_m_from_d$Ta_200[substr(df_met_m_from_d$EPID, 1, 1) == "H"])
summary(df_met_m_from_d$Ta_200[substr(df_met_m_from_d$EPID, 1, 1) == "S"])
source("C:/Users/tnauss/permanent/plygrnd/exploratorien/BE-Meteorology/src/000_set_environment.R")
df_met_d= readRDS(paste0(path_rdata, "/df_met_d.rds"))
df_met_d_meta = readRDS(paste0(path_rdata, "/df_met_d_meta.rds"))
# Check for gaps
if(length(showConnections()) == 0){
cores = 3
cl = parallel::makeCluster(cores)
doParallel::registerDoParallel(cl)
}
path_temp
colnames(df_met_d)[3:51]
v = colnames(df_met_d)[3:51][1]
v
df_met_d$WD
prm = c("Ta_200")
prm = c("Ta_200")
v = prm[1]
v
p = unique(df_met_d$EPID)[1]
p
act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
if(length(act_na) > 0){
p_type = substr(p, 1, 3)
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
# For each consecutive gap, look for all other stations which have no gap for this time span
g_fill = lapply(act_na_grps, function(g){
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)],
training_set_wide[, colnames(training_set_wide) == p],
method = "pls")
fillvalues = predict(model, predicting_set_wide[, -1])
g_fill = list(fillvalues = fillvalues, quality = model$results[model$bestTune$ncomp, ])
return(g_fill)
})
}
act_na
p = unique(df_met_d$EPID)[10]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
act_na
p = unique(df_met_d$EPID)[100]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
act_na
summary(df_met_d$EPID)
summary(df_met_d$Ta_200)
df_met_d$Ta_200
is.na(df_met_d$Ta_200)
df_met_d$EPID[is.na(df_met_d$Ta_200)]
p = unique(df_met_d$EPID)[10]
act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
act_na
if(length(act_na) > 0){
p_type = substr(p, 1, 3)
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
# For each consecutive gap, look for all other stations which have no gap for this time span
g_fill = lapply(act_na_grps, function(g){
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)],
training_set_wide[, colnames(training_set_wide) == p],
method = "pls")
fillvalues = predict(model, predicting_set_wide[, -1])
g_fill = list(fillvalues = fillvalues, quality = model$results[model$bestTune$ncomp, ])
return(g_fill)
})
}
act_na_grps
g = act_na_grps
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
g = act_na_grps[1]
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
g = act_na_grps[[1]]
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)],
training_set_wide[, colnames(training_set_wide) == p],
method = "pls")
training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)]
training_set_wide[, colnames(training_set_wide) == p]
colnames(training_set_wide)
c("datetime", p)
p
!colnames(training_set_wide) %in% c("datetime", p)
colnames(training_set_wide) == p
colnames(training_set_wide) %in% c("datetime", p)]
colnames(training_set_wide) %in% c("datetime", p)
training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)]
training_set_wide[, colnames(training_set_wide) %in% c("datetime", p)]
training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)]
t = training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)]
str(t)
t = training_set_wide[, colnames(training_set_wide) %in% c("datetime", p)]
str(t)
p
colnames(training_set_wide)
colnames(training_set)
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
colnames(training_set_wide)
colnames(predicting_set_wide)
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
unique(training_set$EPID)
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
colnames(training_set_wide)
p
df_met_d$EPID == p
df_met_d[df_met_d$EPID == p, ]
v
df_met_d[df_met_d$EPID == p, which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
colnames(training_set_wide)
response_data = df_met_d[df_met_d$EPID == p, which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
?merge
training_set_wide = merge(training_set_wide, response_data, by="datetime")
training_set_wide = merge(training_set_wide, response_data)
class(training_set_wide)
class(response_data)
colnames(response_data)
colnames(training_set_wide)
class(response_data$datetime)
class(training_set_wide$datetime)
colnames(predicting_set_wide)
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, c(colnames(predicting_set_wide)[-1], p)) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
colnames(training_set_wide)
p
df_met_d$EPID
c(p, colnames(predicting_set_wide)[-1])
p = unique(df_met_d$EPID)[[1]]
p
act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
length(act_na)
act_na
p
p = unique(df_met_d$EPID)[[10]]
act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
p_type = substr(p, 1, 3)
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
g = act_na_grps[1]
g
g = act_na_grps[[1]]
g
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
p
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
c(p, colnames(predicting_set_wide)[-1])
p
as.character(p)
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(as.character(p), colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
colnames(training_set_wide)
colnames(training_set_wide) %in% c("datetime", p)
!colnames(training_set_wide) %in% c("datetime", p)]
!colnames(training_set_wide) %in% c("datetime", p)
colnames(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)])
p
colnames(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))])
colnames(training_set_wide[, colnames(training_set_wide) %in% c("datetime", as.character(p))])
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% c("datetime", as.character(p))],
method = "pls")
training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))]
training_set_wide[, colnames(training_set_wide) %in% c("datetime", as.character(p))]
head(v)
head(training_set_wide[, colnames(training_set_wide) %in% c("datetime", as.character(p))])
head(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))])
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c(as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% c(as.character(p))],
method = "pls")
training_set_wide[, !colnames(training_set_wide) %in% c(as.character(p))]
summary(training_set_wide[, !colnames(training_set_wide) %in% c(as.character(p))])
summary(training_set_wide[, colnames(training_set_wide) %in% c(as.character(p))])
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% c(as.character(p))],
method = "pls")
fillvalues = predict(model, predicting_set_wide[, -1])
g_fill = list(fillvalues = fillvalues, quality = model$results[model$bestTune$ncomp, ])
g_fill
?saveRDS
as.charachter(p)
as.carachter(p)
as.character(p)
as.character(p)
v
path_temp
paste0(path_temp, "g_fill_", v, "_", as.character(p), ".rds")
saveRDS(g_fill, file = paste0(path_temp, "g_fill_", v, "_", as.character(p), ".rds"))
# Set path ---------------------------------------------------------------------
if(Sys.info()["sysname"] == "Windows"){
filepath_base <- "C:/Users/tnauss/permanent/plygrnd/exploratorien/"
} else {
filepath_base <- "/media/permanent/active/exploratorien/"
}
path_data <- paste0(filepath_base, "/data/")
path_forest <- paste0(path_data, "/forest/")
path_lui <- paste0(path_data, "/lui/")
path_smi <- paste0(path_data, "/smi/")
path_plots <- paste0(path_data, "/plots/")
path_releves <- paste0(path_data, "/releves/")
path_rdata <- paste0(path_data, "/rdata/")
path_met_a <- paste0(path_data, "/met_a/")
path_met_m <- paste0(path_data, "/met_m/")
path_met_d <- paste0(path_data, "/met_d/")
path_temp <- paste0(path_data, "/temp/")
path_output <- paste0(path_data, "/output/")
path_vis <- paste0(path_data, "/vis/")
path_plots <- paste0(path_data, "/plots/")
# Set libraries ----------------------------------------------------------------
library(biodivTools) # devtools::install_github("environmentalinformatics-marburg/biodivTools")
library(doParallel)
library(grid)
library(gridExtra)
library(gpm)
library(lavaan)
library(rgeos)
library(ggplot2)
library(mapview)
library(metTools)  # devtools::install_github("environmentalinformatics-marburg/metTools")
library(raster)
library(reshape2)
library(rgdal)
library(satellite)
library(satelliteTools)  # devtools::install_github("environmentalinformatics-marburg/satelliteTools")
library(semPlot)
library(sp)
library(vegan)
library(yaml)
# Other settings ---------------------------------------------------------------
rasterOptions(tmpdir = path_temp)
saga_cmd <- "C:/OSGeo4W64/apps/saga/saga_cmd.exe "
# initOTB("C:/OSGeo4W64/bin/")
initOTB("C:/OSGeo4W64/OTB-5.8.0-win64/OTB-5.8.0-win64/bin/")
df_met_m_from_d = readRDS(paste0(path_rdata, "/df_met_m_from_d.rds"))
df_met_d_meta = readRDS(paste0(path_rdata, "/df_met_d_meta.rds"))
df_met_m_from_d
df_met_m_from_d$aggYear = substr(df_met_m_from_d$datetime, 1, 4)
df_met_m_from_d$aggYear
str(df_met_m_from_d)
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "datetime", "Ta_200", "aggYear")]
head(ta200_stat)
ta200_stat = aggregate(ta200_stat, by=list(ta200_stat$aggYear))
ta200_stat
ta200_stat = aggregate(ta200_stat, by=list(ta200_stat$aggYear), FUN=mean)
head(ta200_stat)
ta200_stat = aggregate(ta200_stat, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "datetime", "Ta_200", "aggYear")]
ta200_stat = aggregate(ta200_stat, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
head(ta200_stat)
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "Ta_200", "aggYear")]
ta200_stat = aggregate(ta200_stat, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
ta200_stat
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "Ta_200", "aggYear")]
ta200_stat = aggregate(ta200_stat$Ta_200, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
ta200_stat
head(ta200_stat)
colnames(ta200_stat) = c("EPID", "Year", "Ta_200")
ta200_stat$Explo = substr(ta200_stat$EPID, 1, 3)
ggplot(ta200_stat, aes(x = Year, y = Ta_200, group = Explo)) +
geom_boxplot(position = "dodge")
ggplot(ta200_stat, aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot(position = "dodge")
df_met_a = read.table(path_met_a, "plot.csv")
df_met_a = read.table(paste0(path_met_a, "plot.csv"))
df_met_a = read.table("C:/Users/tnauss/permanent/plygrnd/exploratorien/data/met_a/plot.csv"))
df_met_a = read.table("C:/Users/tnauss/permanent/plygrnd/exploratorien/data/met_a/plot.csv")
df_met_a = read.table("C:/Users/tnauss/permanent/plygrnd/exploratorien/data/met_a/plots.csv")
head(df_met_a)
df_met_a = read.table("C:/Users/tnauss/permanent/plygrnd/exploratorien/data/met_a/plots.csv", sep = ",", dec = ".", header = TRUE)
head(df_met_a)
ta_stat_a = aggregate(df_met_a$Ta_200, by = list(df_met_a$plotID, df_met_a$datetime), FUN=mean)
ta_stat_a
head(ta_stat_a)
colnames(ta200_stat) = c("EPID", "Year", "Ta_200")
ta_stat_a = aggregate(df_met_a$Ta_200, by = list(df_met_a$plotID, df_met_a$datetime), FUN=mean)
colnames(ta_stat_a) = c("EPID", "Year", "Ta_200")
head(ta_stat_a)
ta_stat_a$Explo = substr(ta_stat_a$EPID, 1, 3)
ggplot(ta_stat_a, aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot(position = "dodge")
ggplot(ta_stat_a, aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot()
ggplot(ta_stat_a[ta_stat_a$EPID!="AET"], aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot()
ggplot(ta_stat_a[ta_stat_a$EPID!="AET", ], aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot()
ggplot(ta_stat_a[!ta_stat_a$EPID %in% c("AET", "HET", "SET"), ], aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot()
ta_stat_a$EPID
ggplot(ta_stat_a[!ta_stat_a$Explo %in% c("AET", "HET", "SET"), ], aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot()
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "Ta_200", "aggYear")]
ta200_stat = aggregate(ta200_stat$Ta_200, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
colnames(ta200_stat) = c("EPID", "Year", "Ta_200")
ta200_stat$Explo = substr(ta200_stat$EPID, 1, 3)
?tapply
tapply(ta200_stat$Ta_200, list(ta200_stat$Year, ta200_stat$Explo), summary)
tapply(ta200_stat$Ta_200, ta200_stat$Explo), summary)
tapply(ta200_stat$Ta_200, ta200_stat$Explo, summary)
ta200_stat$Year
ta200_stat = ta200_stat[ta200_stat$Year == "2010", ]
tapply(ta200_stat$Ta_200, ta200_stat$Explo, summary)
head(ta200_stat)
df_met_m_from_d$aggYear = substr(df_met_m_from_d$datetime, 1, 4)
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "Ta_200", "aggYear")]
ta200_stat = aggregate(ta200_stat$Ta_200, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
colnames(ta200_stat) = c("EPID", "Year", "Ta_200")
ta200_stat$Explo = substr(ta200_stat$EPID, 1, 3)
ggplot(ta200_stat, aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot(position = "dodge")
head(df_met_m_from_d)
path_met_h <- paste0(path_data, "/met_h/")
# Read datasets
df_met_h = be_io_met_daily(paste0(path_met_h, "/plots.csv"))
head(df_met_h)
tail(df_met_h)
head(g_belc)
levels(df_met_h$g_belc)
df_met_h$g_belc = factor(df_met_h$g_belc, levels = c("AEG", "HEG", "SEG",
"AEW", "HEW", "SEW",
"AET", "HET", "SET"))
head(df_met_h)
tail(df_met_h)
# Write datasets
saveRDS(df_met_h, paste0(path_rdata, "/df_met_h.rds"))
# Read datasets
df_met_h = be_io_met_daily(paste0(path_met_h, "/plots.csv"))
df_met_h$g_belc = factor(df_met_h$g_belc, levels = c("AEG", "HEG", "SEG",
"AEW", "HEW", "SEW",
"AET", "HET", "SET"))
head(df_met_h)
tail(df_met_h)
# Write datasets
saveRDS(df_met_h, paste0(path_rdata, "/df_met_h.rds"))
head(df_met_h)
# Check for gaps
if(length(showConnections()) == 0){
cores = 3
cl = parallel::makeCluster(cores)
doParallel::registerDoParallel(cl)
}
prm = c("Ta_200")
v = prm[[1]]
unique(df_met_d$EPID
)
unique(df_met_h$EPID)
unique(df_met_h$EPID)[[1]]
p = unique(df_met_h$EPID)[[1]]
act = df_met_h[df_met_h$EPID == p, ]
act
act_na = which(is.na(act[, which(colnames(df_met_h) == v)]))
act_na
str(act_na)
clasS(act_na)
class(act_na)
head(act)
act
act[!is.na(act$Ta_200)]
act[!is.na(act$Ta_200),]
p_type = substr(p, 1, 3)
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
act_na_grps
str(act_na_grps)
length(act_na_grps)
g = act_na_grps[[1]]
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_h[df_met_h$EPID != p &
grepl(p_type, df_met_h$EPID) &
df_met_h$datetime %in% timespan_fill &
!is.na(df_met_h[, which(colnames(df_met_h) == v)]),
which(colnames(df_met_h) %in% c("EPID", "datetime", v))]
predicting_set
timespan_fill
head(predicting_set)
tail(predicting_set)
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
head(predicting_set)
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
head(predicting_set_wide)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
head(predicting_set_wide)
predicting_set_wide[order(predicting_set_wide$datetime),]
head(predicting_set_wide[order(predicting_set_wide$datetime),])
# Get training dataset
training_set = df_met_h[df_met_h$EPID %in% c(as.character(p), colnames(predicting_set_wide)[-1]) &
!is.na(df_met_h[, which(colnames(df_met_h) == v)]),
which(colnames(df_met_h) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
head(training_set_wide)
head(predicting_set_wide)
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% c(as.character(p))],
method = "pls")
model
fillvalues = predict(model, predicting_set_wide[, -1])
g_fill = list(fillvalues = fillvalues, quality = model$results[model$bestTune$ncomp, ])
saveRDS(g_fill, file = paste0(path_temp, "g_fill_", v, "_", as.character(p), ".rds"))
