act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
act_na
if(length(act_na) > 0){
p_type = substr(p, 1, 3)
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
# For each consecutive gap, look for all other stations which have no gap for this time span
g_fill = lapply(act_na_grps, function(g){
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)],
training_set_wide[, colnames(training_set_wide) == p],
method = "pls")
fillvalues = predict(model, predicting_set_wide[, -1])
g_fill = list(fillvalues = fillvalues, quality = model$results[model$bestTune$ncomp, ])
return(g_fill)
})
}
act_na_grps
g = act_na_grps
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
g = act_na_grps[1]
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
g = act_na_grps[[1]]
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)],
training_set_wide[, colnames(training_set_wide) == p],
method = "pls")
training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)]
training_set_wide[, colnames(training_set_wide) == p]
colnames(training_set_wide)
c("datetime", p)
p
!colnames(training_set_wide) %in% c("datetime", p)
colnames(training_set_wide) == p
colnames(training_set_wide) %in% c("datetime", p)]
colnames(training_set_wide) %in% c("datetime", p)
training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)]
training_set_wide[, colnames(training_set_wide) %in% c("datetime", p)]
training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)]
t = training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)]
str(t)
t = training_set_wide[, colnames(training_set_wide) %in% c("datetime", p)]
str(t)
p
colnames(training_set_wide)
colnames(training_set)
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
colnames(training_set_wide)
colnames(predicting_set_wide)
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
unique(training_set$EPID)
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
colnames(training_set_wide)
p
df_met_d$EPID == p
df_met_d[df_met_d$EPID == p, ]
v
df_met_d[df_met_d$EPID == p, which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
colnames(training_set_wide)
response_data = df_met_d[df_met_d$EPID == p, which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
?merge
training_set_wide = merge(training_set_wide, response_data, by="datetime")
training_set_wide = merge(training_set_wide, response_data)
class(training_set_wide)
class(response_data)
colnames(response_data)
colnames(training_set_wide)
class(response_data$datetime)
class(training_set_wide$datetime)
colnames(predicting_set_wide)
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, c(colnames(predicting_set_wide)[-1], p)) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
colnames(training_set_wide)
p
df_met_d$EPID
c(p, colnames(predicting_set_wide)[-1])
p = unique(df_met_d$EPID)[[1]]
p
act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
length(act_na)
act_na
p
p = unique(df_met_d$EPID)[[10]]
act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
p_type = substr(p, 1, 3)
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
g = act_na_grps[1]
g
g = act_na_grps[[1]]
g
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
p
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
c(p, colnames(predicting_set_wide)[-1])
p
as.character(p)
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(as.character(p), colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
colnames(training_set_wide)
colnames(training_set_wide) %in% c("datetime", p)
!colnames(training_set_wide) %in% c("datetime", p)]
!colnames(training_set_wide) %in% c("datetime", p)
colnames(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)])
p
colnames(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))])
colnames(training_set_wide[, colnames(training_set_wide) %in% c("datetime", as.character(p))])
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% c("datetime", as.character(p))],
method = "pls")
training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))]
training_set_wide[, colnames(training_set_wide) %in% c("datetime", as.character(p))]
head(v)
head(training_set_wide[, colnames(training_set_wide) %in% c("datetime", as.character(p))])
head(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))])
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c(as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% c(as.character(p))],
method = "pls")
training_set_wide[, !colnames(training_set_wide) %in% c(as.character(p))]
summary(training_set_wide[, !colnames(training_set_wide) %in% c(as.character(p))])
summary(training_set_wide[, colnames(training_set_wide) %in% c(as.character(p))])
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% c(as.character(p))],
method = "pls")
fillvalues = predict(model, predicting_set_wide[, -1])
g_fill = list(fillvalues = fillvalues, quality = model$results[model$bestTune$ncomp, ])
g_fill
?saveRDS
as.charachter(p)
as.carachter(p)
as.character(p)
as.character(p)
v
path_temp
paste0(path_temp, "g_fill_", v, "_", as.character(p), ".rds")
saveRDS(g_fill, file = paste0(path_temp, "g_fill_", v, "_", as.character(p), ".rds"))
# Set path ---------------------------------------------------------------------
if(Sys.info()["sysname"] == "Windows"){
filepath_base <- "C:/Users/tnauss/permanent/plygrnd/exploratorien/"
} else {
filepath_base <- "/media/permanent/active/exploratorien/"
}
path_data <- paste0(filepath_base, "/data/")
path_forest <- paste0(path_data, "/forest/")
path_lui <- paste0(path_data, "/lui/")
path_smi <- paste0(path_data, "/smi/")
path_plots <- paste0(path_data, "/plots/")
path_releves <- paste0(path_data, "/releves/")
path_rdata <- paste0(path_data, "/rdata/")
path_met_a <- paste0(path_data, "/met_a/")
path_met_m <- paste0(path_data, "/met_m/")
path_met_d <- paste0(path_data, "/met_d/")
path_temp <- paste0(path_data, "/temp/")
path_output <- paste0(path_data, "/output/")
path_vis <- paste0(path_data, "/vis/")
path_plots <- paste0(path_data, "/plots/")
# Set libraries ----------------------------------------------------------------
library(biodivTools) # devtools::install_github("environmentalinformatics-marburg/biodivTools")
library(doParallel)
library(grid)
library(gridExtra)
library(gpm)
library(lavaan)
library(rgeos)
library(ggplot2)
library(mapview)
library(metTools)  # devtools::install_github("environmentalinformatics-marburg/metTools")
library(raster)
library(reshape2)
library(rgdal)
library(satellite)
library(satelliteTools)  # devtools::install_github("environmentalinformatics-marburg/satelliteTools")
library(semPlot)
library(sp)
library(vegan)
library(yaml)
# Other settings ---------------------------------------------------------------
rasterOptions(tmpdir = path_temp)
saga_cmd <- "C:/OSGeo4W64/apps/saga/saga_cmd.exe "
# initOTB("C:/OSGeo4W64/bin/")
initOTB("C:/OSGeo4W64/OTB-5.8.0-win64/OTB-5.8.0-win64/bin/")
df_met_m_from_d = readRDS(paste0(path_rdata, "/df_met_m_from_d.rds"))
df_met_d_meta = readRDS(paste0(path_rdata, "/df_met_d_meta.rds"))
df_met_m_from_d
df_met_m_from_d$aggYear = substr(df_met_m_from_d$datetime, 1, 4)
df_met_m_from_d$aggYear
str(df_met_m_from_d)
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "datetime", "Ta_200", "aggYear")]
head(ta200_stat)
ta200_stat = aggregate(ta200_stat, by=list(ta200_stat$aggYear))
ta200_stat
ta200_stat = aggregate(ta200_stat, by=list(ta200_stat$aggYear), FUN=mean)
head(ta200_stat)
ta200_stat = aggregate(ta200_stat, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "datetime", "Ta_200", "aggYear")]
ta200_stat = aggregate(ta200_stat, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
head(ta200_stat)
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "Ta_200", "aggYear")]
ta200_stat = aggregate(ta200_stat, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
ta200_stat
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "Ta_200", "aggYear")]
ta200_stat = aggregate(ta200_stat$Ta_200, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
ta200_stat
head(ta200_stat)
colnames(ta200_stat) = c("EPID", "Year", "Ta_200")
ta200_stat$Explo = substr(ta200_stat$EPID, 1, 3)
ggplot(ta200_stat, aes(x = Year, y = Ta_200, group = Explo)) +
geom_boxplot(position = "dodge")
ggplot(ta200_stat, aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot(position = "dodge")
df_met_a = read.table(path_met_a, "plot.csv")
df_met_a = read.table(paste0(path_met_a, "plot.csv"))
df_met_a = read.table("C:/Users/tnauss/permanent/plygrnd/exploratorien/data/met_a/plot.csv"))
df_met_a = read.table("C:/Users/tnauss/permanent/plygrnd/exploratorien/data/met_a/plot.csv")
df_met_a = read.table("C:/Users/tnauss/permanent/plygrnd/exploratorien/data/met_a/plots.csv")
head(df_met_a)
df_met_a = read.table("C:/Users/tnauss/permanent/plygrnd/exploratorien/data/met_a/plots.csv", sep = ",", dec = ".", header = TRUE)
head(df_met_a)
ta_stat_a = aggregate(df_met_a$Ta_200, by = list(df_met_a$plotID, df_met_a$datetime), FUN=mean)
ta_stat_a
head(ta_stat_a)
colnames(ta200_stat) = c("EPID", "Year", "Ta_200")
ta_stat_a = aggregate(df_met_a$Ta_200, by = list(df_met_a$plotID, df_met_a$datetime), FUN=mean)
colnames(ta_stat_a) = c("EPID", "Year", "Ta_200")
head(ta_stat_a)
ta_stat_a$Explo = substr(ta_stat_a$EPID, 1, 3)
ggplot(ta_stat_a, aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot(position = "dodge")
ggplot(ta_stat_a, aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot()
ggplot(ta_stat_a[ta_stat_a$EPID!="AET"], aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot()
ggplot(ta_stat_a[ta_stat_a$EPID!="AET", ], aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot()
ggplot(ta_stat_a[!ta_stat_a$EPID %in% c("AET", "HET", "SET"), ], aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot()
ta_stat_a$EPID
ggplot(ta_stat_a[!ta_stat_a$Explo %in% c("AET", "HET", "SET"), ], aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot()
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "Ta_200", "aggYear")]
ta200_stat = aggregate(ta200_stat$Ta_200, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
colnames(ta200_stat) = c("EPID", "Year", "Ta_200")
ta200_stat$Explo = substr(ta200_stat$EPID, 1, 3)
?tapply
tapply(ta200_stat$Ta_200, list(ta200_stat$Year, ta200_stat$Explo), summary)
tapply(ta200_stat$Ta_200, ta200_stat$Explo), summary)
tapply(ta200_stat$Ta_200, ta200_stat$Explo, summary)
ta200_stat$Year
ta200_stat = ta200_stat[ta200_stat$Year == "2010", ]
tapply(ta200_stat$Ta_200, ta200_stat$Explo, summary)
head(ta200_stat)
df_met_m_from_d$aggYear = substr(df_met_m_from_d$datetime, 1, 4)
ta200_stat = df_met_m_from_d[, colnames(df_met_m_from_d) %in% c("EPID", "Ta_200", "aggYear")]
ta200_stat = aggregate(ta200_stat$Ta_200, by=list(ta200_stat$EPID, ta200_stat$aggYear), FUN=mean)
colnames(ta200_stat) = c("EPID", "Year", "Ta_200")
ta200_stat$Explo = substr(ta200_stat$EPID, 1, 3)
ggplot(ta200_stat, aes(x = Year, y = Ta_200, fill = Explo)) +
geom_boxplot(position = "dodge")
head(df_met_m_from_d)
path_met_h <- paste0(path_data, "/met_h/")
# Read datasets
df_met_h = be_io_met_daily(paste0(path_met_h, "/plots.csv"))
head(df_met_h)
tail(df_met_h)
head(g_belc)
levels(df_met_h$g_belc)
df_met_h$g_belc = factor(df_met_h$g_belc, levels = c("AEG", "HEG", "SEG",
"AEW", "HEW", "SEW",
"AET", "HET", "SET"))
head(df_met_h)
tail(df_met_h)
# Write datasets
saveRDS(df_met_h, paste0(path_rdata, "/df_met_h.rds"))
# Read datasets
df_met_h = be_io_met_daily(paste0(path_met_h, "/plots.csv"))
df_met_h$g_belc = factor(df_met_h$g_belc, levels = c("AEG", "HEG", "SEG",
"AEW", "HEW", "SEW",
"AET", "HET", "SET"))
head(df_met_h)
tail(df_met_h)
# Write datasets
saveRDS(df_met_h, paste0(path_rdata, "/df_met_h.rds"))
head(df_met_h)
# Check for gaps
if(length(showConnections()) == 0){
cores = 3
cl = parallel::makeCluster(cores)
doParallel::registerDoParallel(cl)
}
prm = c("Ta_200")
v = prm[[1]]
unique(df_met_d$EPID
)
unique(df_met_h$EPID)
unique(df_met_h$EPID)[[1]]
p = unique(df_met_h$EPID)[[1]]
act = df_met_h[df_met_h$EPID == p, ]
act
act_na = which(is.na(act[, which(colnames(df_met_h) == v)]))
act_na
str(act_na)
clasS(act_na)
class(act_na)
head(act)
act
act[!is.na(act$Ta_200)]
act[!is.na(act$Ta_200),]
p_type = substr(p, 1, 3)
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
act_na_grps
str(act_na_grps)
length(act_na_grps)
g = act_na_grps[[1]]
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_h[df_met_h$EPID != p &
grepl(p_type, df_met_h$EPID) &
df_met_h$datetime %in% timespan_fill &
!is.na(df_met_h[, which(colnames(df_met_h) == v)]),
which(colnames(df_met_h) %in% c("EPID", "datetime", v))]
predicting_set
timespan_fill
head(predicting_set)
tail(predicting_set)
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
head(predicting_set)
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
head(predicting_set_wide)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
head(predicting_set_wide)
predicting_set_wide[order(predicting_set_wide$datetime),]
head(predicting_set_wide[order(predicting_set_wide$datetime),])
# Get training dataset
training_set = df_met_h[df_met_h$EPID %in% c(as.character(p), colnames(predicting_set_wide)[-1]) &
!is.na(df_met_h[, which(colnames(df_met_h) == v)]),
which(colnames(df_met_h) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
head(training_set_wide)
head(predicting_set_wide)
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% c(as.character(p))],
method = "pls")
model
fillvalues = predict(model, predicting_set_wide[, -1])
g_fill = list(fillvalues = fillvalues, quality = model$results[model$bestTune$ncomp, ])
saveRDS(g_fill, file = paste0(path_temp, "g_fill_", v, "_", as.character(p), ".rds"))
if(length(showConnections()) == 0){
cores = 3
cl = parallel::makeCluster(cores)
doParallel::registerDoParallel(cl)
}
source("C:/Users/tnauss/permanent/plygrnd/exploratorien/BE-Meteorology/src/000_set_environment.R")
dwd_station_groups = data.frame(EP=rep(c("AE", "HE", "SE"),each=5),
stid = c("3278", "3402", "2814", "2074", "4887",
"6305", "7368", "1297", "0896", "1270",
"0164", "1869", "7351", "5745", "7389"))
be_files = list.files(path_rdata, pattern = glob2rx("df_met_be_h_*.rds"), full.names = TRUE)
e = be_files[[1]]
df_met_h = readRDS(e)
df_met_h$datetime = as.POSIXct(df_met_h$datetime)
prm = c("Ta_200", "rH_200")
v = prm[[1]]
dsv = paste0("ds", v)
hmv = paste0(v, "_hmean")
act_ep = dwd_station_groups[dwd_station_groups$EP == (substr(df_met_h$EPID[1], 1, 2)),]
act_dwd_files = list.files(path_rdata, pattern = glob2rx(paste0("*dwd_h_", v, "*.rds")), full.names = TRUE)
act_dwd_files = act_dwd_files[(substr(basename(act_dwd_files), nchar(basename(act_dwd_files))-7, nchar(basename(act_dwd_files))-4) %in% act_ep$stid)]
dwd = lapply(act_dwd_files, function(f){
af = readRDS(f)
af = af[, c("datetime", "STATIONS_ID", dsv)]
return(af)
})
dwd = do.call("rbind", dwd)
dwd_wide = dcast(dwd, datetime ~ STATIONS_ID, value.var = dsv)
colnames(dwd_wide)[-1] = paste0(dsv, "_", colnames(dwd_wide)[-1])
p = unique(df_met_h$EPID)[[1]]
act_station = df_met_h[df_met_h$EPID == p, c("EPID", "datetime", v, "qualitycounter")]
act_station$agg = substr(act_station$datetime, 6, 13)
vmean = aggregate(act_station[, v] ~ act_station[, "agg"], FUN=mean, na.rm=TRUE)
colnames(vmean) = c("agg2", hmv)
c = colnames(vmean)
for(a in vmean$agg2){
act_station[act_station$agg == a, c[1]] = vmean[vmean$agg == a, c[1]]
act_station[act_station$agg == a, c[2]] = vmean[vmean$agg == a, c[2]]
}
if(all(act_station$agg == act_station$agg2)){
act_station$agg2 = NULL
}
act_station[, dsv] = act_station[, v] - act_station[, hmv]
act_na = which(is.na(act_station[, dsv]))
length(act_na)
timespan_fill = act_station$datetime[act_na]
predictor_set_wide = dwd_wide[dwd_wide$datetime %in% timespan_fill,]
training_set_wide = dwd_wide[!dwd_wide$datetime %in% timespan_fill,]
training_set_wide[, as.character(p)] = act_station[!act_station$datetime %in% timespan_fill,v]
# Create training folds
stf = CreateSpacetimeFolds(training_set_wide, spacevar = NA, timevar = "datetime", k = 10,
seed = 10)
trCntr <- trainControl(method="cv",
index = stf$training_index,
indexOut = stf$training_indexOut,
returnResamp = "all",
repeats = 1, verbose = FALSE)
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% as.character(p)],
method = "pls",
trControl = trCntr)
pls = model
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% as.character(p)],
method = "gam",
trControl = trCntr)
gam = model
gam
pls
v
head(training_set_wide[, colnames(training_set_wide) %in% as.character(p)])
head(act_station)
head(act_station[!is.na(act_station$Ta_200),])
head(predictor_set_wide)
head(training_set_wide)
timespan_fill = act_station$datetime[act_na]
predictor_set_wide = dwd_wide[dwd_wide$datetime %in% timespan_fill,]
training_set_wide = dwd_wide[!dwd_wide$datetime %in% timespan_fill,]
training_set_wide[, as.character(p)] = act_station[!act_station$datetime %in% timespan_fill,dsv]
# Create training folds
stf = CreateSpacetimeFolds(training_set_wide, spacevar = NA, timevar = "datetime", k = 10,
seed = 10)
trCntr <- trainControl(method="cv",
index = stf$training_index,
indexOut = stf$training_indexOut,
returnResamp = "all",
repeats = 1, verbose = FALSE)
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% as.character(p)],
method = "gam",
trControl = trCntr)
if(length(showConnections()) == 0){
cores = 3
cl = parallel::makeCluster(cores)
doParallel::registerDoParallel(cl)
}
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", as.character(p))],
training_set_wide[, colnames(training_set_wide) %in% as.character(p)],
method = "pls",
trControl = trCntr)
