shannon = as.data.frame(shannon)
shannon$EPID = rownames(shannon)
eveness =as.data.frame(eveness)
eveness$EPID = rownames(eveness)
out = aggregate(act$Cover, by=list(act$EPID), FUN = sum)
names(out) = c("EPID", "total.cover.cum")
out = merge(out, shannon, by = "EPID")
out = merge(out, eveness, by = "EPID")
out$Year = y
out$Layer = l
return(out)
})
divyear = do.call("rbind", divyear)
})
forest_diversity = do.call("rbind", forest_diversity)
saveRDS(forest_diversity, paste0(path_rdata, "/forest_diversity.rds"))
df_met_d = be_io_met_daily(paste0(path_data, "/met_d/plots.csv"))
df_met_d = df_met_d[df_met_d$datetime >= as.POSIXct("2009-01-01") & df_met_d$datetime <= as.POSIXct("2016-12-31"), ]
df_met_d = df_met_d[!df_met_d$g_belc %in% c("AET", "HET", "SET"), ]
df_met_d$g_belc = factor(df_met_d$g_belc, levels = c("AEG", "HEG", "SEG",
"AEW", "HEW", "SEW"))
df_met_d_meta = read.table(paste0(path_data, "/met_d/sensor_description.csv"),
sep = ",", header = TRUE)
df_met_m = be_io_met_monthly(paste0(path_met_m, "/2008_2018_a28b5cd71110d9b5/plots.csv"))
df_met_a = be_io_met_annual(paste0(path_data, "met_a/plots.csv"))
df_met_m_meta = read.table(paste0(path_met_m, "/2008_2018_a28b5cd71110d9b5/sensor_description.csv"),
sep = ",", header = TRUE)
df_lut = readBExplLUT(paste0(path_lui, "lut.csv"))
df_lui = readBExpLUI(paste0(path_lui, "/LUI_glob_sep_22.02.2018+224004.txt"))
df_smi = readBExpSMI(paste0(path_smi, "/17746_Forest_EP_SMI_Silvicultural_management_intensity_index_1.2.2/17746.txt"))
df_sst = readBExpStandStruc(paste0(path_smi, "/20106_Forest_EP_Stand_structural_attributes_core_SSA_1.2.2/20106.txt"))
# df_vegrel = readBExpVegReleves(paste0(path_releves, "/19686_Vegetation Records for Grassland EPs, 2008 - 2016_1.7.13/19686.txt"))
# df_vegrel = compSpecRichBExpVegReleves(df_vegrel)
df_veghead = readBExpVegHeaderData(paste0(path_releves, "Vegetation_Header_Data_2008-2016.csv"))
df_vegforest = readRDS(paste0(path_rdata, "/forest_diversity.rds"))
df_met_d_g = merge(df_met_d, df_lui, by.x = c("EPID", "g_a"), by.y = c("EPID", "Year"))
df_met_d_g = merge(df_met_d_g, df_veghead, by.x = c("EPID", "g_a"), by.y = c("EPID", "Year"))
df_met_d_g = merge(df_met_d_g, df_lut, by.x = c("EPID", "g_a"), by.y = c("EPID", "year"), all.x = TRUE)
df_met_d_g$EPID = droplevels(df_met_d_g$EPID)
length(unique(df_met_d_g$EPID)) == 150
df_met_m_g = merge(df_met_m, df_lui, by.x = c("EPID", "g_a"), by.y = c("EPID", "Year"))
df_met_m_g = merge(df_met_m_g, df_veghead, by.x = c("EPID", "g_a"), by.y = c("EPID", "Year"))
df_met_m_g = merge(df_met_m_g, df_lut, by.x = c("EPID", "g_a"), by.y = c("EPID", "year"), all.x = TRUE)
df_met_m_g$EPID = droplevels(df_met_m_g$EPID)
length(unique(df_met_m_g$EPID)) == 150
df_met_d_w = merge(df_met_d, df_smi, by.x = c("EPID"), by.y = c("EPID"))
df_met_d_w = merge(df_met_d_w, df_sst, by.x = c("EPID"), by.y = c("EPID"))
df_met_d_w = merge(df_met_d_w, df_vegforest, by.x = c("EPID"), by.y = c("EPID"))
df_met_d_w$EPID = droplevels(df_met_d_w$EPID)
length(unique(df_met_d_w$EPID)) == 150
df_met_m_w = merge(df_met_m, df_smi, by.x = c("EPID"), by.y = c("EPID"))
df_met_m_w = merge(df_met_m_w, df_sst, by.x = c("EPID"), by.y = c("EPID"))
df_met_m_w = merge(df_met_m_w, df_vegforest, by.x = c("EPID"), by.y = c("EPID"))
df_met_m_w$EPID = droplevels(df_met_m_w$EPID)
length(unique(df_met_m_w$EPID)) == 150
source("C:/Users/tnauss/permanent/plygrnd/exploratorien/BE-Meteorology/src/00_set_environment.R")
# Read datasets
df_met_d_g = readRDS(paste0(path_rdata, "/df_met_d_g.rds"))
df_met_d_w = readRDS(paste0(path_rdata, "/df_met_d_w.rds"))
df_met_m_g = readRDS(paste0(path_rdata, "/df_met_m_g.rds"))
df_met_m_w = readRDS(paste0(path_rdata, "/df_met_m_w.rds"))
df_met_d_meta = readRDS(paste0(path_rdata, "/df_met_d_meta.rds"))
df_met_m_meta = readRDS(paste0(path_rdata, "/df_met_m_meta.rds"))
head(df_met_m_w)
boxplot(df_met_d_g$Ta_200)
boxplot(df_met_m_g$Ta_200)
boxplot(df_met_m_g$Ta_200_min)
plot(df_met_m_g$Ta_200)
df_met_m_g$Ta_200
summary(df_met_m_g)
df_met_d_g[is.na(df_met_m_g$Ta_200), ]
df_met_d_g[df_met_d_g$EPID == "AEG",]
df_met_d_g[df_met_d_g$EPID == "AEG", ]
df_met_d_g[df_met_d_g$EPID == "AEG01", ]
df_met_d = be_io_met_daily(paste0(path_data, "/met_d/plots.csv"))
df_met_d = df_met_d[df_met_d$datetime >= as.POSIXct("2009-01-01") & df_met_d$datetime <= as.POSIXct("2016-12-31"), ]
df_met_d = df_met_d[!df_met_d$g_belc %in% c("AET", "HET", "SET"), ]
df_met_d$g_belc = factor(df_met_d$g_belc, levels = c("AEG", "HEG", "SEG",
"AEW", "HEW", "SEW"))
df_met_d_meta = read.table(paste0(path_data, "/met_d/sensor_description.csv"),
sep = ",", header = TRUE)
df_met_m = be_io_met_monthly(paste0(path_met_m, "/2008_2018_a28b5cd71110d9b5/plots.csv"))
df_met_a = be_io_met_annual(paste0(path_data, "met_a/plots.csv"))
df_met_m_meta = read.table(paste0(path_met_m, "/2008_2018_a28b5cd71110d9b5/sensor_description.csv"),
sep = ",", header = TRUE)
saveRDS(df_met_d, paste0(path_rdata, "/df_met_d.rds"))
saveRDS(df_met_d_meta, paste0(path_rdata, "/df_met_d_meta.rds"))
saveRDS(df_met_m, paste0(path_rdata, "/df_met_m.rds"))
saveRDS(df_met_m_meta, paste0(path_rdata, "/df_met_m_meta.rds"))
head(df_met_d)
which(colnames(df_met_d) == v)
v = "Ta_200"
which(colnames(df_met_d) == v)
act = df_met_d[df_met_d$EPID == p, which(colnames(df_met_d) == v)]
p = "AEG01"
act
act = df_met_d[df_met_d$EPID == p, which(colnames(df_met_d) == v)]
act
head(act)
act = df_met_d[df_met_d$EPID == p, c(1, which(colnames(df_met_d) == v))]
act
act = df_met_d[df_met_d$EPID == p, ]
act
act$datetime
is.na(act[, p])
is.na(act[, which(colnames(df_met_d) == v)])
which(is.na(act[, which(colnames(df_met_d) == v)]))
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
act_na = c(act_na, c(201, 202))
tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
act_na_grps
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
act_na_grps
# For each consecutive gap, look for all other stations which have no gap for this time span
all = df_met_d[df_met_d$EPID != p, ]
act_na_grps = act$datetime[act_na_grps]
act$datetime
act_na_grps
g = act_na_grps[[1]]
g
act_na_grps = act$datetime[g]
timespan = act$datetime[g]
timespan
timespan_fill = act$datetime[g]
timespan_fill
all = df_met_d[df_met_d$EPID != p & df_met_d$datetime %in% timespan_fill, ]
all
ind_epid = df_met_d[df_met_d$EPID != p &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]), "EPID"]
ind_epid
unique(ind_epid)
ind_epid = unique(df_met_d[df_met_d$EPID != p &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]), "EPID"])
ind_epid
timespan_training =
which(colnames(df_met_d) == v)
timespan_training =
which(colnames(df_met_d) == v)
which(colnames(df_met_d) == v)
which(colnames(df_met_d) %in% c("EPID", "datetime", v)
)
# Get training time span
df_met_d[df_met_d$EPID %in% c(p, ind_epid) & !is.na(df_met_d[, which(colnames(df_met_d) == v)]), which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set = df_met_d[df_met_d$EPID %in% c(p, ind_epid) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
timespan_fill
ind_epid
predictin_set = df_met_d[df_met_d$EPID != p &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, unique(predictin_set$EPID)) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
unique(predictin_set$EPID)
unique(training_set$EPID)
predicting_set = df_met_d[df_met_d$EPID != p &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
p
predicting_set = df_met_d[df_met_d$EPID != p &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
unique(predictin_set$EPID)
unique(predicting_set$EPID)
unique(training_set$EPID)
c(p, unique(predictin_set$EPID))
predictin_set$EPID
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, unique(as.character(predictin_set$EPID))) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
c(p, unique(predictin_set$EPID))
predictin_set$EPID
str(predictin_set$EPID)
str(df_met_d$EPID)
df_met_d$EPID = as.character(df_met_d$EPID)
act = df_met_d[df_met_d$EPID == p, ]
# Identify gaps in actual station EPID and split gaps if not consecutive
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, unique(predictin_set$EPID)) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
unique(training_set$EPID)
unique(predictin_set$EPID)
c(p, unique(predictin_set$EPID))
c(p, unique(predicting_set$EPID))
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, unique(predicting_set$EPID)) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
unique(training_set$EPID)
unique(predicting_set$EPID)
training_set
?cast
?ffs
str(training_set)
dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
which(!colnames(training_set_wide) == p)
colnames(training_set_wide) == p
which(!colnames(training_set_wide) == p)
model = ffs(training_set_wide$Ta_200[which(!colnames(training_set_wide) == p)],
which(colnames(training_set_wide) == p), method = "pls")
training_set_wide$Ta_200[which(!colnames(training_set_wide) == p)]
training_set_wide$Ta_200[which(colnames(training_set_wide) == p)]
training_set_wide$Ta_200
which(colnames(training_set_wide) == p)
training_set_wide[, which(!colnames(training_set_wide) == p)]
training_set_wide[, which(colnames(training_set_wide) == p)]
model = ffs(training_set_wide[, which(!colnames(training_set_wide) == p)],
training_set_wide[, which(colnames(training_set_wide) == p)],
method = "pls")
str(training_set_wide)
head(training_set_wide[, which(!colnames(training_set_wide) == p)])
head(training_set_wide[, which(colnames(training_set_wide) == p)])
predicting_set
c(p, unique(predicting_set$EPID))
which(colnames(df_met_d) == v)
colnames(df_met_d)
!is.na(df_met_d[, which(colnames(df_met_d) == v)])
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, unique(predicting_set$EPID)) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
head(training_set)
summary(training_set)
summary(training_set_wide)
is.na(training_set_wide)
any(is.na(training_set_wide))
which(is.na(training_set_wide))
training_set_wide[2923]
training_set_wide
summary(training_set)
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
head(training_set_wide)
df_met_d$EPID %in% c(p, unique(predicting_set$EPID))
training_set_wide = complete.cases(training_set_wide)
str(training_set_wide)
complete.cases(training_set_wide)
?complete.cases
complete.cases(training_set_wide[, -1])
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
model = ffs(training_set_wide[, which(!colnames(training_set_wide) == p)],
training_set_wide[, which(colnames(training_set_wide) == p)],
method = "pls")
training_set_wide[, which(!colnames(training_set_wide) == p)]
model = ffs(training_set_wide[, c(-1, which(!colnames(training_set_wide) == p))],
training_set_wide[, c(-1, which(colnames(training_set_wide) == p))],
method = "pls")
training_set_wide$datetime == NULL
model = ffs(training_set_wide[, c(which(!colnames(training_set_wide) == p))],
training_set_wide[, c(which(colnames(training_set_wide) == p))],
method = "pls")
training_set_wide$datetime = NULL
model = ffs(training_set_wide[, c(which(!colnames(training_set_wide) == p))],
training_set_wide[, c(which(colnames(training_set_wide) == p))],
method = "pls")
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
model = ffs(training_set_wide[, c(which(!colnames(training_set_wide) == c("datetime", p)))],
training_set_wide[, c(which(colnames(training_set_wide) == p))],
method = "pls")
p_type = substr(p, 1, 3)
grepl(df_met_d$EPID, p_type)
grepl(p_type, df_met_d$EPID)
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID),
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID),
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
# Read datasets
df_met_d= readRDS(paste0(path_rdata, "/df_met_d.rds"))
df_met_d$EPID = as.character(df_met_d$EPID)
# Identify gaps in actual station EPID and split gaps if not consecutive
act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
g = act_na_grps[[1]]
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID),
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, unique(predicting_set$EPID)) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
colnames(training_set_wide)
model = ffs(training_set_wide[, c(which(!colnames(training_set_wide) == c("datetime", p)))],
training_set_wide[, c(which(colnames(training_set_wide) == p))],
method = "pls")
model
head(predicting_set)
head(predicting_set_wide)
fillvalues = predict(model, predicting_set[, -1])
predicting_set[ , colSums(is.na(predicting_set)) == 0]
predicting_set = predicting_set[ , colSums(is.na(predicting_set)) == 0]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
head(predicting_set_wide)
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
colSums(is.na(predicting_set))
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
head(predicting_set_wide)
colnames(predicting_set_wide)
colnames(predicting_set_wide)[-1]
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
head(training_set_wide)
colnames(training_set_wide)
colnames(predicting_set_wide)
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
# Compute model
model = ffs(training_set_wide[, c(which(!colnames(training_set_wide) == c("datetime", p)))],
training_set_wide[, c(which(colnames(training_set_wide) == p))],
method = "pls")
model
fillvalues = predict(model, predicting_set[, -1])
predicting_set[, -1]
fillvalues = predict(model, predicting_set_wide[, -1])
fillvalues
plot(fillvalues)
# Read datasets
df_met_d = be_io_met_daily(paste0(path_data, "/met_d/plots.csv"))
source("C:/Users/tnauss/permanent/plygrnd/exploratorien/BE-Meteorology/src/000_set_environment.R")
df_met_d = be_io_met_daily(paste0(path_data, "/met_d/plots.csv"))
df_met_d = df_met_d[df_met_d$datetime >= as.POSIXct("2009-01-01") & df_met_d$datetime <= as.POSIXct("2016-12-31"), ]
df_met_d = df_met_d[!df_met_d$g_belc %in% c("AET", "HET", "SET"), ]
df_met_d$g_belc = factor(df_met_d$g_belc, levels = c("AEG", "HEG", "SEG",
"AEW", "HEW", "SEW"))
df_met_d_meta = read.table(paste0(path_data, "/met_d/sensor_description.csv"),
sep = ",", header = TRUE)
saveRDS(df_met_d, paste0(path_rdata, "/df_met_d.rds"))
saveRDS(df_met_d_meta, paste0(path_rdata, "/df_met_d_meta.rds"))
saveRDS(df_met_m, paste0(path_rdata, "/df_met_m.rds"))
saveRDS(df_met_m_meta, paste0(path_rdata, "/df_met_m_meta.rds"))
# Check for gaps
head(df_met_d)
p = "AEG01"
p_type = substr(p, 1, 3)
v = "Ta_200"
# Identify gaps in actual station EPID and split gaps if not consecutive
act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
act_na
act_na == 0
# Identify gaps in actual station EPID and split gaps if not consecutive
lapply(unique(df_met_d$EPID), function(p){
act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
if(length(act_na) > 0){
print(p)
}
})
p = "AEG10"
p_type = substr(p, 1, 3)
v = "Ta_200"
act = df_met_d[df_met_d$EPID == p, ]
act_na = which(is.na(act[, which(colnames(df_met_d) == v)]))
act_na
act_na_grps = tapply(act_na, cumsum(c(TRUE, diff(act_na) != 1)), identity)
act_na_grps
g = act_na_grps[[◙1]]
g = act_na_grps[[1]]
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
timespan_fill
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
p_type = substr(p, 1, 3)
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
# Compute model
model = ffs(training_set_wide[, c(which(!colnames(training_set_wide) == c("datetime", p)))],
training_set_wide[, c(which(colnames(training_set_wide) == p))],
method = "pls")
model
fillvalues = predict(model, predicting_set_wide[, -1])
colnames(training_set_wide)
p
colnames(training_set_wide[, c(which(!colnames(training_set_wide) == c("datetime", p)))])
c(which(!colnames(training_set_wide) == c("datetime", p)))
c(which(!colnames(training_set_wide) == c("datetime", p)))
colnames(predicting_set_wide)
colnames(training_set)
colnames(training_set_wide)
?ffs
head(training_set_wide[, c(which(!colnames(training_set_wide) == c("datetime", p)))])
colnames(training_set_wide)
c("datetime", p) %in% colnames(training_set_wide)
colnames(training_set_wide) %in% c("datetime", p)
head(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)])
colnames(training_set_wide) == p
head(training_set_wide[, colnames(training_set_wide) == p])
colnames(training_set_wide) == p
# Compute model
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)],
training_set_wide[, colnames(training_set_wide) == p],
method = "pls")
model
fillvalues = predict(model, predicting_set_wide[, -1])
fillvalues
timespan_fill
fillvalues
plot(fillvalues, timespan_fill)
plot(timespan_fill, fillvalues)
plot(timespan_fill, fillvalues, type = "l")
model
model$results
model$bestTune
model$results[model$bestTune, ]
model$results
str(model$results)
str(model$bestTune)
model$results[model$bestTune$ncomp, ]
fillvalues
# Compute model
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)],
training_set_wide[, colnames(training_set_wide) == p],
method = "nnet")
model
g_fill = list(fillvalues = fillvalues, quality = model$results[model$bestTune$ncomp, ])
act_na_grps
act$datetime[g]
# For each consecutive gap, look for all other stations which have no gap for this time span
g_fill = lapply(act_na_grps, function(g){
# Get stations which cover gap time span
timespan_fill = act$datetime[g]
predicting_set = df_met_d[df_met_d$EPID != p &
grepl(p_type, df_met_d$EPID) &
df_met_d$datetime %in% timespan_fill &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
predicting_set_wide = dcast(predicting_set, datetime ~ EPID, value.var=v)
predicting_set_wide = predicting_set_wide[ , colSums(is.na(predicting_set_wide)) == 0]
# Get training dataset
training_set = df_met_d[df_met_d$EPID %in% c(p, colnames(predicting_set_wide)[-1]) &
!is.na(df_met_d[, which(colnames(df_met_d) == v)]),
which(colnames(df_met_d) %in% c("EPID", "datetime", v))]
training_set_wide = dcast(training_set, datetime ~ EPID, value.var=v)
training_set_wide = training_set_wide[complete.cases(training_set_wide[, -1]), ]
# Compute model and predict values
model = ffs(training_set_wide[, !colnames(training_set_wide) %in% c("datetime", p)],
training_set_wide[, colnames(training_set_wide) == p],
method = "nnet")
fillvalues = predict(model, predicting_set_wide[, -1])
g_fill = list(fillvalues = fillvalues, quality = model$results[model$bestTune$ncomp, ])
return(g_fill)
})
